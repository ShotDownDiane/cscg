{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Django\n",
    "from utils import from_home\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG     = Config() # main config\n",
    "CFG.src = Config() # sub-config for NL intents\n",
    "CFG.tgt = Config() # sub-config for source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DJANGO_DIR = from_home('workspace/ml-data/msc-research/raw-datasets/testing')\n",
    "EMB_DIR = from_home('workspace/ml-data/msc-research/embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.dataset_config = Config()\n",
    "CFG.dataset_config.__dict__ = {\n",
    "    'root_dir': DJANGO_DIR,\n",
    "    'anno_min_freq': 1,\n",
    "    'code_min_freq': 1,\n",
    "    'anno_seq_maxlen': 10,\n",
    "    'code_seq_maxlen': 10,\n",
    "    'emb_file': os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle')\n",
    "}\n",
    "\n",
    "django = Django(config=CFG.dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(django)):\n",
    "    print(django.raw(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "django[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(config: Namespace):\n",
    "    emb = nn.Embedding(len(config.lang), config.emb_size, padding_idx=config.lang.pad_idx)\n",
    "    \n",
    "    if config.load_pretrained_emb:\n",
    "        emb.weight = nn.Parameter(torch.tensor(config.emb_matrix, dtype=torch.float32))\n",
    "        emb.weight.requires_grad = False\n",
    "        \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config: Namespace):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # 1. ENCODER\n",
    "        self.src_embedding = get_embeddings(config.src)\n",
    "        self.encoder = nn.LSTM(input_size=config.src.emb_size,\n",
    "                               hidden_size=config.src.hidden_size,\n",
    "                               dropout=config.src.lstm_dropout,\n",
    "                               bidirectional=True,\n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.decoder_cell_init = nn.Linear(in_features=2*config.src.hidden_size,\n",
    "                                           out_features=config.tgt.hidden_size)\n",
    "        \n",
    "        # 2. ATTENTION\n",
    "        # project source encoding to decoder rnn's h space\n",
    "        self.att_src_linear = nn.Linear(in_features=2*config.src.hidden_size,\n",
    "                                        out_features=config.tgt.hidden_size,\n",
    "                                        bias=False)\n",
    "        \n",
    "        # transformation of decoder hidden states and context vectors before reading out target words\n",
    "        # this produces the `attentional vector` in (Luong et al., 2015)\n",
    "        self.att_vec_linear = nn.Linear(in_features=2*config.src.hidden_size + config.tgt.hidden_size,\n",
    "                                        out_features=config.tgt.hidden_size,\n",
    "                                        bias=False)\n",
    "        \n",
    "        # 3. DECODER\n",
    "        self.tgt_embedding = get_embeddings(config.tgt)\n",
    "        self.decoder = nn.LSTMCell(input_size=config.tgt.emb_size + config.tgt.hidden_size,\n",
    "                                   hidden_size=config.tgt.hidden_size)\n",
    "       \n",
    "        # prob layer over target language\n",
    "        self.readout = nn.Linear(in_features=config.tgt.hidden_size,\n",
    "                                 out_features=len(config.tgt.lang),\n",
    "                                 bias=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.tgt.dropout_p)\n",
    "        \n",
    "        # save the entire config\n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        src: bs, max_src_len\n",
    "        tgt: bs, max_tgt_len\n",
    "        \"\"\"\n",
    "        enc_out, (h0_dec, c0_dec) = self.encode(src)\n",
    "        scores, att_mats = self.decode(enc_out, h0_dec, c0_dec, tgt)\n",
    "        \n",
    "        return scores, (h0_dec, c0_dec), att_mats\n",
    "    \n",
    "    \n",
    "    def encode(self, src):\n",
    "        \"\"\"\n",
    "        src : bs x max_src_len (emb look-up indices)\n",
    "        out : bs x max_src_len x 2*hid_size\n",
    "        h/c0: bs x tgt_hid_size\n",
    "        \"\"\"\n",
    "        emb = self.src_embedding(src)\n",
    "        out, (hn, cn) = self.encoder(emb)\n",
    "        \n",
    "        c0_dec = self.decoder_cell_init(torch.cat([cn[0], cn[1]], dim=1))\n",
    "        h0_dec = c0_dec.tanh()\n",
    "        \n",
    "        return out, (h0_dec, c0_dec)\n",
    "    \n",
    "    \n",
    "    def decode(self, src_enc, h0_dec, c0_dec, tgt):\n",
    "        \"\"\"\n",
    "        src_enc: bs, max_src_len, 2*hid_size (== encoder output)\n",
    "        h/c0   : bs, tgt_hid_size\n",
    "        tgt    : bs, max_tgt_len (emb look-up indices)\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        scores = []\n",
    "        att_mats = []\n",
    "        \n",
    "        emb = self.tgt_embedding(tgt) # bs, max_tgt_len, tgt_emb_size\n",
    "        \n",
    "        att_vec = torch.zeros(batch_size, self.config.tgt.hidden_size, requires_grad=False)\n",
    "        src_enc_att = self.att_src_linear(src_enc) # bs, max_src_len, tgt_hid_size\n",
    "        \n",
    "        hidden = (h0_dec, c0_dec)\n",
    "        \n",
    "        for t in range(tgt_len):\n",
    "            emb_t = emb[:, t, :]\n",
    "            x = torch.cat([emb_t, att_vec], dim=-1)\n",
    "            h_t, c_t = self.decoder(x, hidden)\n",
    "\n",
    "            ctx_t, _, att_mat = self.luong_attention(h_t, src_enc, src_enc_att)\n",
    "            \n",
    "            # Luong eq. (5)\n",
    "            att_t = self.att_vec_linear(torch.cat([h_t, ctx_t], dim=1))\n",
    "            att_t = att_t.tanh() \n",
    "            att_t = self.dropout(att_t)\n",
    "            \n",
    "            # Luong eq. (6)\n",
    "            score_t = self.readout(att_t)\n",
    "            score_t = F.softmax(score_t, dim=-1)\n",
    "            \n",
    "            scores   += [score_t]\n",
    "            att_mats += [att_mat]\n",
    "            \n",
    "            # for next state t+1\n",
    "            att_vec = att_t\n",
    "            hidden  = h_t, c_t\n",
    "        \n",
    "        return torch.stack(scores), att_mats[:-1]\n",
    "            \n",
    "        \n",
    "    def luong_attention(self, h_t, src_enc, src_enc_att, mask=None):\n",
    "        \"\"\"\n",
    "        h_t        : bs, hid_size\n",
    "        src_enc    : bs, max_src_len, 2*src_hid_size\n",
    "        src_enc_att: bs, max_src_len, tgt_hid_size\n",
    "        mask       : bs, max_src_len\n",
    "        \n",
    "        ctx_vec    : bs, 2*src_hid_size\n",
    "        att_weight : bs, max_src_len\n",
    "        att_mat    : bs, 1, max_src_len\n",
    "        \"\"\"\n",
    "        \n",
    "        # bs x src_max_len\n",
    "        att_weight = torch.bmm(src_enc_att, h_t.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        if mask:\n",
    "            att_weight.data.masked_fill_(mask, -np.inf)\n",
    "        \n",
    "        att_mat = att_weight.view((att_weight.size(0), 1, att_weight.size(1)))\n",
    "        att_weight = F.softmax(att_weight, dim=-1) # alignment\n",
    "\n",
    "        att_view = (att_weight.size(0), 1, att_weight.size(1))\n",
    "        ctx_vec = torch.bmm(att_weight.view(*att_view), src_enc).squeeze(1)\n",
    "\n",
    "        return ctx_vec, att_weight, att_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.pad_idx = 0\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "    \n",
    "cfg = Namespace()\n",
    "\n",
    "cfg.src = Namespace()\n",
    "cfg.src.lang = Lang()\n",
    "cfg.src.emb_size = 50\n",
    "cfg.src.load_pretrained_emb = False\n",
    "cfg.src.hidden_size = 128\n",
    "cfg.src.lstm_dropout = 0\n",
    "\n",
    "cfg.tgt = Namespace()\n",
    "cfg.tgt.lang = Lang()\n",
    "cfg.tgt.emb_size = 50\n",
    "cfg.tgt.load_pretrained_emb = False\n",
    "cfg.tgt.hidden_size = 128\n",
    "cfg.tgt.dropout_p = 0.1\n",
    "\n",
    "\n",
    "model = Model(cfg)\n",
    "x = torch.randint(10, size=(17, 20))\n",
    "y = torch.randint(15, size=(17, 10))\n",
    "\n",
    "s, a = model(x, y)\n",
    "s[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cg_model = ... (y -> x)\n",
    "cs_model = ... (x -> y)\n",
    "\n",
    "for x, y in data:\n",
    "    y_ = cs_model(x)\n",
    "    x_ = cg_model(y)\n",
    "    \n",
    "    lxy   = ...\n",
    "    lyx   = ...\n",
    "    ldual = ...\n",
    "    latt1 = ...\n",
    "    latt2 = ...\n",
    "    latt  = l1 + l2\n",
    "    \n",
    "    lcs = lxy + a1*ldual + b1*latt\n",
    "    lcg = lyx + a2*ldual + b2*latt\n",
    "    \n",
    "    lcs.backward()\n",
    "    lcg.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
