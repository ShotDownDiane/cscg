{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation as a Dual Task of Code Summarization\n",
    "\n",
    "<img src='https://i.imgur.com/RqN1agC.png' width='600' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "- https://blog.floydhub.com/attention-mechanism/\n",
    "- https://github.com/Bolin0215/CSCGDual\n",
    "\n",
    "**Dataset:** https://github.com/wanyao1992/code_summarization_public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "$x \\; \\text{: code snippets}, \\; y \\; \\text{: comments}$\n",
    "\n",
    "$P(x,y) = \\color{#00a010}{P(x) \\cdot P(y|x)} = \\color{#a010a0}{P(y) \\cdot P(x|y)}$\n",
    "\n",
    "### Loss terms\n",
    "\n",
    "$l_{xy} = -\\frac{1}{m} \\sum_{t=1}^{m} P(y_t | y_{\\lt t}, x)$\n",
    "\n",
    "$l_{yx} = -\\frac{1}{n} \\sum_{t=1}^{n} P(x_t | x_{\\lt t}, y)$\n",
    "\n",
    "$l_{dual}=\\left[ \\left(\\color{#00a010}{\\log\\hat{P}(x) + \\log P(y \\vert x; \\theta_{xy})} \\right) - \\left(\\color{#a010a0}{\\log\\hat{P}(y) + \\log P(x \\vert y; \\theta_{yx})} \\right) \\right]^{2} \\text{ : regularization term}$\n",
    "\n",
    "$l_{att} = l_1 + l_2, \\text{ where } l_k = \\mathcal{D}_{JS} \\left( b_i, b_i' \\right ) = \\frac{1}{2n}\\sum_{i=1}^{n} \\mathcal{D}_{KL} \\left(b_i \\, || \\, \\frac{b_i + b_i'}{2} \\right) + \\mathcal{D}_{KL} \\left(b_i' \\, || \\, \\frac{b_i + b_i'}{2} \\right)$\n",
    "\n",
    "$b_i = softmax \\left( A_{xy}[i, :] \\right), \\; b_i' = softmax \\left( A_{yx}[i, :] \\right)$\n",
    "\n",
    "$A_{xy} \\in \\mathbb{R}^{n \\times m}, \\; A_{yx} \\in \\mathbb{R}^{m \\times n} \\text{ : attention weights}$\n",
    "\n",
    "### Updates\n",
    "\n",
    "$\\text{Minibatch of } k \\text{ pairs: } \\langle \\left(x_i, y_i\\right) \\rangle_{i=1}^{k}$\n",
    "\n",
    "$\n",
    "\\begin{cases}\n",
    "G_{xy} = \\nabla_{\\theta_{xy}} \\frac{1}{k} \\sum_{i=1}^{k} \\left( l_{xy} + \\lambda_{dual}^{(1)} \\cdot l_{dual} + \\lambda_{att}^{(1)} \\cdot l_{att} \\right)\\\\\n",
    "G_{yx} = \\nabla_{\\theta_{yx}} \\frac{1}{k} \\sum_{i=1}^{k} \\left( l_{yx} + \\lambda_{dual}^{(2)} \\cdot l_{dual} + \\lambda_{att}^{(2)} \\cdot l_{att} \\right)\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$\\text{Update } \\theta_{xy} \\text{ and } \\theta_{yx} \\text{ independently}$\n",
    "\n",
    "### Notes\n",
    "- The last encoder's hidden state is used to init the decoder's hidden state.\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR    = '/home/alex/workspace/msc-research/embeddings'\n",
    "DJANGO_DIR = '/home/alex/workspace/msc-research/raw-datasets/django/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = Namespace()\n",
    "HP.batch_size = 5\n",
    "HP.epochs     = 1\n",
    "\n",
    "HP.dataset_config = Namespace()\n",
    "HP.dataset_config.__dict__ = {\n",
    "    'root_dir': DJANGO_DIR,\n",
    "    'anno_min_freq': 1,\n",
    "    'code_min_freq': 1,\n",
    "    'anno_seq_maxlen': 40,\n",
    "    'code_seq_maxlen': 40,\n",
    "    'emb_file': os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle')\n",
    "}\n",
    "\n",
    "django = Django(config=HP.dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, input_maxlen, emb_matrix, num_layers=1, bidir=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size  = hidden_size\n",
    "        self.input_maxlen = input_maxlen\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.bidir = bidir\n",
    "        \n",
    "        self.vocab_size, self.emb_dim = emb_matrix.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(emb_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.bidir_lstm = nn.LSTM(input_size=self.emb_dim,\n",
    "                                  hidden_size=self.hidden_size,\n",
    "                                  num_layers=self.num_layers,\n",
    "                                  bidirectional=self.bidir,\n",
    "                                  batch_first=True)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size=x.shape[0])\n",
    "            \n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.bidir_lstm(emb)\n",
    "            \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        d = 2 if self.bidir else 1\n",
    "        z = torch.zeros(d * self.num_layers, batch_size, self.hidden_size)\n",
    "        return (z,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS = 512\n",
    "L = 40\n",
    "enc = Encoder(hidden_size=HS, \n",
    "              input_maxlen=L, \n",
    "              emb_matrix=django.anno_lang.emb_matrix, \n",
    "              bidir=True, \n",
    "              num_layers=1)\n",
    "\n",
    "print(enc)\n",
    "\n",
    "bs = 17\n",
    "x = torch.randint(L, size=(bs, L))\n",
    "out, (h, c) = enc(x)\n",
    "print('out:', out.shape, 'h:', h.shape, 'c:', c.shape)\n",
    "\n",
    "h = h.permute((1, 0, 2)).reshape(bs, -1)\n",
    "# torch.isclose(out[:, -1], h)\n",
    "assert torch.isclose(out[:, -1, :HS], h[:, :HS]).all()\n",
    "assert torch.isclose(out[:, 0, HS:], h[:, HS:]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luong Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        \n",
    "        self.W = nn.Linear(enc_hidden_size, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, ht, hs):\n",
    "        # ht: decoder output: (batch_size, 1, hidden_size)\n",
    "        # hs: encoder output: (batch_size, seq_len, hidden_size)\n",
    "        # score: (batch_size, 1, seq_len)\n",
    "        \n",
    "        score   = torch.bmm(ht, self.W(hs).transpose(1, 2))\n",
    "        align   = F.softmax(score, dim=-1)\n",
    "        context = torch.bmm(align, hs)\n",
    "        \n",
    "        return context, align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = LuongAttention(2*HS, HS)\n",
    "print(att)\n",
    "d = torch.rand(bs, 1, HS)\n",
    "c, a = att(d, out)\n",
    "print('context', c.shape)\n",
    "print('align', a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "- maybe no code embeddings?\n",
    "- Coarse-to-Fine does not use code embeddings (only input + sketch embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, enc_hidden_size, dec_hidden_size, num_layers=1, bidir=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim) # one hot\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.bidir = bidir\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.emb_dim,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidir,\n",
    "                            batch_first=True)\n",
    "        \n",
    "#         self.linear = nn.Linear()\n",
    "        \n",
    "        self.attention = LuongAttention(enc_hidden_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        context, align = self.attention(hidden, enc_output)\n",
    "        \n",
    "        emb = self.embedding(x)\n",
    "        \n",
    "        lstm_in = torch.cat((emb, context), dim=-1)\n",
    "        \n",
    "        output, hidden = self.lstm(lstm_in, hidden)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(1000, size=(1,40))\n",
    "\n",
    "enc = Encoder(hidden_size=512, \n",
    "              input_maxlen=40, \n",
    "              emb_matrix=django.anno_lang.emb_matrix, \n",
    "              bidir=True, \n",
    "              num_layers=1)\n",
    "\n",
    "dec = Decoder(1000, 50, 1024, 512, 1, False)\n",
    "out, (h, c) = enc(x)\n",
    "\n",
    "inp = torch.randint(40, size=(17, 50))\n",
    "output, hidden = dec(inp, h, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(django.raw_example(1337))\n",
    "\n",
    "# s = []\n",
    "# for i in django.X[1337]:\n",
    "#     s += [django.anno_lang.index2word[i]]\n",
    "# print(' '.join(s))\n",
    "\n",
    "# s = []\n",
    "# for i in django.Y[1337]:\n",
    "#     s += [django.code_lang.index2word[i]]\n",
    "# print(' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_pt_glove, build_embedding_matrix\n",
    "\n",
    "emb_dict = load_pt_glove(os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle'))\n",
    "e1 = django.anno_lang.emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in 'this is a test return if self object'.split():\n",
    "    assert np.isclose(emb_dict[w], e1[django.anno_lang.word2index[w]]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = django[12]\n",
    "print(x)\n",
    "print(y)\n",
    "django.raw_example(12)\n",
    "django.anno_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "django.code_lang.word2count.most_common()[-100:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cg_model = ... (y -> x)\n",
    "cs_model = ... (x -> y)\n",
    "\n",
    "for x, y in data:\n",
    "    y_ = cs_model(x)\n",
    "    x_ = cg_model(y)\n",
    "    \n",
    "    lxy   = ...\n",
    "    lyx   = ...\n",
    "    ldual = ...\n",
    "    latt1 = ...\n",
    "    latt2 = ...\n",
    "    latt  = l1 + l2\n",
    "    \n",
    "    lcs = lxy + a1*ldual + b1*latt\n",
    "    lcg = lyx + a2*ldual + b2*latt\n",
    "    \n",
    "    lcs.backward()\n",
    "    lcg.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
