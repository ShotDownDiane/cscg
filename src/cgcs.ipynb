{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation as a Dual Task of Code Summarization\n",
    "\n",
    "```\n",
    "@article{wei2019code,\n",
    "  title={Code Generation as a Dual Task of Code Summarization},\n",
    "  author={Wei, Bolin and Li, Ge and Xia, Xin and Fu, Zhiyi and Jin, Zhi},\n",
    "  journal={arXiv preprint arXiv:1910.05923},\n",
    "  year={2019}\n",
    "}\n",
    "```\n",
    "\n",
    "<img src='https://i.imgur.com/RqN1agC.png' width='600' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "- https://blog.floydhub.com/attention-mechanism/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "$x \\; \\text{: code snippets}, \\; y \\; \\text{: comments}$\n",
    "\n",
    "$P(x,y) = \\color{#00a010}{P(x) \\cdot P(y|x)} = \\color{#a010a0}{P(y) \\cdot P(x|y)}$\n",
    "\n",
    "### Loss terms\n",
    "\n",
    "$l_{xy} = -\\frac{1}{m} \\sum_{t=1}^{m} P(y_t | y_{\\lt t}, x)$\n",
    "\n",
    "$l_{yx} = -\\frac{1}{n} \\sum_{t=1}^{n} P(x_t | x_{\\lt t}, y)$\n",
    "\n",
    "$l_{dual}=\\left[ \\left(\\color{#00a010}{\\log\\hat{P}(x) + \\log P(y \\vert x; \\theta_{xy})} \\right) - \\left(\\color{#a010a0}{\\log\\hat{P}(y) + \\log P(x \\vert y; \\theta_{yx})} \\right) \\right]^{2} \\text{ : regularization term}$\n",
    "\n",
    "$l_{att} = l_1 + l_2, \\text{ where } l_k = \\mathcal{D}_{JS} \\left( b_i, b_i' \\right ) = \\frac{1}{2n}\\sum_{i=1}^{n} \\mathcal{D}_{KL} \\left(b_i \\, || \\, \\frac{b_i + b_i'}{2} \\right) + \\mathcal{D}_{KL} \\left(b_i' \\, || \\, \\frac{b_i + b_i'}{2} \\right)$\n",
    "\n",
    "$b_i = softmax \\left( A_{xy}[i, :] \\right), \\; b_i' = softmax \\left( A_{yx}[i, :] \\right)$\n",
    "\n",
    "$A_{xy} \\in \\mathbb{R}^{n \\times m}, \\; A_{yx} \\in \\mathbb{R}^{m \\times n} \\text{ : attention weights}$\n",
    "\n",
    "### Updates\n",
    "\n",
    "$\\text{Minibatch of } k \\text{ pairs: } \\langle \\left(x_i, y_i\\right) \\rangle_{i=1}^{k}$\n",
    "\n",
    "$\n",
    "\\begin{cases}\n",
    "G_{xy} = \\nabla_{\\theta_{xy}} \\frac{1}{k} \\sum_{i=1}^{k} \\left( l_{xy} + \\lambda_{dual}^{(1)} \\cdot l_{dual} + \\lambda_{att}^{(1)} \\cdot l_{att} \\right)\\\\\n",
    "G_{yx} = \\nabla_{\\theta_{yx}} \\frac{1}{k} \\sum_{i=1}^{k} \\left( l_{yx} + \\lambda_{dual}^{(2)} \\cdot l_{dual} + \\lambda_{att}^{(2)} \\cdot l_{att} \\right)\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$\\text{Update } \\theta_{xy} \\text{ and } \\theta_{yx} \\text{ independently}$\n",
    "\n",
    "### Notes\n",
    "- The last encoder's hidden state is used to init the decoder's hidden state.\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Django"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR    = '/home/alex/workspace/msc-research/embeddings'\n",
    "DJANGO_DIR = '/home/alex/workspace/msc-research/raw-datasets/django/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = Namespace()\n",
    "HP.batch_size = 5\n",
    "HP.epochs     = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> clean text\n",
      "> construct vocab\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734ffc7d4d9d4bdf8e13eb9604274065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18805), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d2cf623a44422b59f0f37735dd0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18805), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> tokenize\n",
      "> pad\n",
      "> build emb matrix\n",
      "> load glove from pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d32c2a22039466fa5259c617384109d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11705), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> DONE\n"
     ]
    }
   ],
   "source": [
    "HP.dataset_config = Namespace()\n",
    "HP.dataset_config.__dict__ = {\n",
    "    'root_dir': DJANGO_DIR,\n",
    "    'anno_min_freq': 1,\n",
    "    'code_min_freq': 1,\n",
    "    'anno_seq_maxlen': 40,\n",
    "    'code_seq_maxlen': 40,\n",
    "    'emb_file': os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle')\n",
    "}\n",
    "\n",
    "django = Django(config=HP.dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "<img src='https://i.stack.imgur.com/SjnTl.png' width='500' align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, input_maxlen, emb_matrix, num_layers=1, bidir=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size  = hidden_size\n",
    "        self.input_maxlen = input_maxlen\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.bidir = bidir\n",
    "        \n",
    "        self.vocab_size, self.emb_dim = emb_matrix.shape\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(emb_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.bidir_lstm = nn.LSTM(input_size=self.emb_dim,\n",
    "                                  hidden_size=self.hidden_size,\n",
    "                                  num_layers=self.num_layers,\n",
    "                                  bidirectional=self.bidir,\n",
    "                                  batch_first=True)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size=x.shape[0])\n",
    "            \n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.bidir_lstm(emb)\n",
    "            \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        d = 2 if self.bidir else 1\n",
    "        z = torch.zeros(d * self.num_layers, batch_size, self.hidden_size)\n",
    "        return (z,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([17, 40, 512]) h: torch.Size([1, 17, 512]) c: torch.Size([1, 17, 512])\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(hidden_size=512, input_maxlen=40, emb_matrix=django.emb_matrix, bidir=False, num_layers=1)\n",
    "\n",
    "x = torch.randint(40, size=(17,40))\n",
    "out, (h,c) = enc(x)\n",
    "print('out:', out.shape, 'h:', h.shape, 'c:', c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luong Attention\n",
    "\n",
    "<img src='https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg' width='400' align='left'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        \n",
    "        self.W = nn.Linear(enc_hidden_size, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, ht, hs):\n",
    "        # ht: decoder output: (batch_size, 1, hidden_size)\n",
    "        # hs: encoder output: (batch_size, seq_len, hidden_size)\n",
    "        # scode: (batch_size, 1, seq_len)\n",
    "        \n",
    "        print('ht', ht.shape)\n",
    "        print('hs', hs.shape)\n",
    "        print('whs', self.W(hs).shape)\n",
    "        \n",
    "        score   = torch.bmm(ht, self.W(hs).transpose(1, 2))\n",
    "        align   = F.softmax(score, dim=-1)\n",
    "        context = torch.bmm(align, hs)\n",
    "        \n",
    "        return context, align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ht torch.Size([17, 1, 512])\n",
      "hs torch.Size([17, 40, 512])\n",
      "whs torch.Size([17, 40, 512])\n",
      "torch.Size([17, 1, 512]) torch.Size([17, 1, 40]) tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "att = LuongAttention(512)\n",
    "bs = 17\n",
    "e = torch.rand(bs, 40, 512)\n",
    "d = torch.rand(bs, 1, 512)\n",
    "c, a = att(d, e)\n",
    "print(c.shape, a.shape, a[0, 0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, enc_hidden_size, dec_hidden_size, num_layers=1, bidir=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.bidir = bidir\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.emb_dim,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidir,\n",
    "                            batch_first=True)\n",
    "        \n",
    "#         self.linear = nn.Linear()\n",
    "        \n",
    "        self.attention = LuongAttention(enc_hidden_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        context, align = self.attention(hidden, enc_output)\n",
    "        \n",
    "        emb = self.embedding(x)\n",
    "        \n",
    "        lstm_in = torch.cat((emb, context), dim=-1)\n",
    "        \n",
    "        output, state = self.lstm(lstm_in, hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ht torch.Size([2, 1, 512])\n",
      "hs torch.Size([1, 40, 1024])\n",
      "whs torch.Size([1, 40, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 2 at dimension 0, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-27aca6aa3869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-d9c22014ccc1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-33231dd8486b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ht, hs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'whs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mscore\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0malign\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor to have size 2 at dimension 0, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "x = torch.randint(1000, size=(1,40))\n",
    "\n",
    "enc = Encoder(hidden_size=512, \n",
    "              input_maxlen=40, \n",
    "              emb_matrix=django.emb_matrix, \n",
    "              bidir=True, \n",
    "              num_layers=1)\n",
    "\n",
    "dec = Decoder(1000, 50, 1024, 512, 1, False)\n",
    "out, (h, c) = enc(x)\n",
    "\n",
    "inp = torch.tensor([12])\n",
    "output, hidden = dec(inp, h, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\#\\#\\# TESTING \\#\\#\\#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"parser . add_argument ( 'args' , metavar = 'app_label' , nargs = '+' ,  help = 'One or more application label.' )\",\n",
       " \"parser . add_argument ( 'args' , metavar = 'app_label' , nargs = '+' , help = 'One or more application label.' )\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 2808\n",
    "# n = []\n",
    "x = django.raw_example(j)['code']\n",
    "xx = django.Y[j]\n",
    "xx = xx[xx > 0]\n",
    "x, ' '.join(list(map(lambda i: django.code_tok.index_word[i], xx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> load glove from pickle\n"
     ]
    }
   ],
   "source": [
    "from utils import load_pt_glove\n",
    "e = load_pt_glove(f'{EMB_DIR}/glove.6B.50d.txt.pickle')\n",
    "w = 'object'\n",
    "assert np.isclose(e[w], django.emb_matrix[django.anno_tok.word_index[w]]).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
