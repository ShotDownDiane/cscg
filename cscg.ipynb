{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './language_model/')\n",
    "\n",
    "# for suppressing torch.save warnings\n",
    "# see https://discuss.pytorch.org/t/got-warning-couldnt-retrieve-source-code-for-container/7689\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from django import Django\n",
    "from ml_utils.config import Config\n",
    "from language_model.lm_train import train_language_model\n",
    "from language_model.lm_prob import LMProb\n",
    "\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width=180, indent=2, compact=False)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_home(x):\n",
    "    return os.path.join(os.environ['HOME'], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR   = from_home('workspace/ml-data/msc-research')\n",
    "# DJANGO_DIR = os.path.join(ROOT_DIR, 'raw-datasets/testing') # simple django\n",
    "DJANGO_DIR = os.path.join(ROOT_DIR, 'raw-datasets/django')\n",
    "EMB_DIR    = os.path.join(ROOT_DIR, 'embeddings')\n",
    "\n",
    "CFG = Config() # main config\n",
    "\n",
    "# sub-config for dataset\n",
    "CFG.dataset_config = Config()\n",
    "CFG.dataset_config.__dict__ = {\n",
    "    'root_dir': DJANGO_DIR,\n",
    "    'anno_min_freq': 1,\n",
    "    'code_min_freq': 1,\n",
    "    'anno_seq_maxlen': 30,\n",
    "    'code_seq_maxlen': 20,\n",
    "    'emb_file': os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle'),\n",
    "}\n",
    "\n",
    "dataset = Django(config=CFG.dataset_config)\n",
    "\n",
    "# sub-config for NL intents\n",
    "CFG.anno = Config() \n",
    "CFG.anno.__dict__ = {\n",
    "    'lstm_hidden_size': 128,\n",
    "    'lstm_dropout_p': 0.0,\n",
    "    'att_dropout_p': 0.0,\n",
    "    'lang': dataset.anno_lang,\n",
    "    'load_pretrained_emb': True,\n",
    "    'emb_size': 50,\n",
    "}\n",
    "\n",
    "# sub-config for source code\n",
    "CFG.code = Config() \n",
    "CFG.code.__dict__ = {\n",
    "    'lstm_hidden_size': 128,\n",
    "    'lstm_dropout_p': 0.0,\n",
    "    'att_dropout_p': 0.0,\n",
    "    'lang': dataset.code_lang,\n",
    "    'load_pretrained_emb': False,\n",
    "    'emb_size': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = dataset.code_lang.to_numeric('return func(1+a)', tokenize_mode='code', pad_mode='post', max_len=10)\n",
    "ws = dataset.code_lang.to_tokens(torch.tensor(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(dataset))\n",
    "a, c = dataset[i]\n",
    "assert len(a) == CFG.dataset_config.anno_seq_maxlen, f'{i}'\n",
    "assert len(c) == CFG.dataset_config.code_seq_maxlen, f'{i}'\n",
    "pp.pprint(a)\n",
    "pp.pprint(dataset.anno_lang.to_tokens(a))\n",
    "print('-'*120)\n",
    "pp.pprint(c)\n",
    "pp.pprint(dataset.code_lang.to_tokens(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute LM probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train/test/valid splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = dataset.train_test_valid_split(test_p=1/len(dataset), valid_p=1/len(dataset), seed=42)\n",
    "splits = dataset.train_test_valid_split(test_p=0.1, valid_p=0.2, seed=42)\n",
    "\n",
    "for kind in splits:\n",
    "    for t in splits[kind]:\n",
    "        vs = splits[kind][t]\n",
    "        vs = torch.cat(vs)\n",
    "        vs = vs[vs != 0]\n",
    "        splits[kind][t] = vs\n",
    "        \n",
    "# splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train language model\n",
    "\n",
    "**Note:** Must do this for both anno and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.language_model = Config()\n",
    "CFG.language_model.__dict__ = {\n",
    "    'dataset'     : 'django',\n",
    "    'model'       : 'LSTM', # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU, Transformer)\n",
    "    'n_head'      : None,   # number of heads in the enc/dec of the Transformers\n",
    "    'emb_size'    : 32,     # size of the word embeddings\n",
    "    'n_hid'       : 64,     # number of hidden units per layer\n",
    "    'n_layers'    : 1,      # number of layers\n",
    "    'lr'          : 0.25,    # initial learning rate\n",
    "    'clip'        : 0.25,   # gradient clipping\n",
    "    'dropout_p'   : 0.0,    # dropout applied to layers\n",
    "    'tied'        : False,  # whether to tie the word embeddings and softmax weights\n",
    "    'log_interval': 100,\n",
    "    'epochs'      : 50, # upper epoch limit\n",
    "    'batch_size'  : 32,\n",
    "    'seed'        : None # for reproducibility\n",
    "}\n",
    "\n",
    "CFG.language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_cfg = CFG.language_model\n",
    "\n",
    "for kind in ['anno', 'code']:\n",
    "    print(f'Training LM for {kind}\\n')\n",
    "\n",
    "    lm_cfg.kind = kind\n",
    "    lm_cfg.bptt = CFG.dataset_config.__dict__[f'{kind}_seq_maxlen'] # seq len\n",
    "    lm_cfg.save_path = f'./data/lm/lm-{lm_cfg.dataset}-{lm_cfg.kind}.pt' # path to save the final model\n",
    "    \n",
    "#     train_language_model(lm_cfg, \n",
    "#                          num_tokens=len(getattr(dataset, f'{kind}_lang')),\n",
    "#                          train_nums=torch.stack(splits[kind]['train']),\n",
    "#                          test_nums=torch.stack(splits[kind]['test']),\n",
    "#                          valid_nums=torch.stack(splits[kind]['valid']))\n",
    "    \n",
    "    train_language_model(lm_cfg, \n",
    "                         num_tokens=len(getattr(dataset, f'{kind}_lang')),\n",
    "                         train_nums=splits[kind]['train'],\n",
    "                         test_nums=splits[kind]['test'],\n",
    "                         valid_nums=splits[kind]['valid'])\n",
    "    \n",
    "    print('*' * 120, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute LM probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_root_dir = './data/lm'\n",
    "lm_paths = {\n",
    "    'anno': f'{lm_root_dir}/lm-{lm_cfg.dataset}-anno.pt',\n",
    "    'code': f'{lm_root_dir}/lm-{lm_cfg.dataset}-code.pt'\n",
    "}\n",
    "\n",
    "for f in lm_paths.values():\n",
    "    assert os.path.exists(f), f'Language Model: file <{f}> does not exist!'\n",
    "    \n",
    "# _ = dataset.compute_lm_probs(lm_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLMProb:\n",
    "    def __init__(self, model_path):        \n",
    "        self.model = torch.load(open(model_path, 'rb'), map_location={'cuda:0': 'cpu'})\n",
    "        self.model = self.model.cpu()\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_prob(self, nums, verbose=False):\n",
    "        with torch.no_grad():\n",
    "            inp = torch.tensor([int(nums[0])]).long().unsqueeze(0)\n",
    "            hidden = self.model.init_hidden(bsz=1)\n",
    "            log_probs = []\n",
    "            \n",
    "            for i in range(1, len(nums)):\n",
    "                output, hidden = self.model(inp, hidden)\n",
    "                \n",
    "                #word_weights = output.squeeze().data.double().exp()\n",
    "                #prob = word_weights[nums[i]] / word_weights.sum()\n",
    "                probs = F.softmax(output.squeeze(), dim=-1)\n",
    "                prob = probs[nums[i]]\n",
    "                \n",
    "                # append current log prob\n",
    "                log_probs += [torch.log(prob)]\n",
    "                inp.data.fill_(int(nums[i]))\n",
    "\n",
    "            if verbose:\n",
    "                for i in range(len(log_probs)):\n",
    "                    print(f'{nums[i+1]:4d}: P(w|s) = {np.exp(log_probs[i]):8.4f} | logP(w|s) = {log_probs[i]:8.4f}')\n",
    "                print(f'=> sum_prob = {sum(log_probs):.4f}')\n",
    "\n",
    "        return sum(log_probs) / len(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probs = {'anno': [], 'code': []}\n",
    "\n",
    "pad_idx = {\n",
    "    'anno': dataset.anno_lang.token2index['<pad>'],\n",
    "    'code': dataset.code_lang.token2index['<pad>']\n",
    "} \n",
    "\n",
    "for kind in lm_probs:\n",
    "    lm = MyLMProb(lm_paths[kind])\n",
    "    p = pad_idx[kind]\n",
    "\n",
    "    for vec in tqdm(getattr(dataset, kind), total=len(dataset), desc=f'P({kind})'):\n",
    "        lm_probs[kind] += [np.exp(lm.get_prob(vec[vec != pad_idx[kind]], verbose=False))]\n",
    "    \n",
    "    lm_probs[kind] = sum(lm_probs[kind])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = 'anno'\n",
    "lm = MyLMProb(lm_paths[kind])\n",
    "s = {}\n",
    "for t, i in tqdm(getattr(dataset, f'{kind}_lang').token2index.items()):\n",
    "    if i in [0, 2, 3]:\n",
    "        continue\n",
    "    q = torch.tensor([2, i, 3])\n",
    "    s[i] = np.exp(lm.get_prob(q))\n",
    "    \n",
    "xs, ys = zip(*sorted(s.items(), key=lambda k: -k[1]))\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(xs, ys)\n",
    "plt.xticks(xs, rotation=90)\n",
    "\n",
    "sum(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual CS/CG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(config: Config):\n",
    "    emb = nn.Embedding(len(config.lang), config.emb_size, padding_idx=config.lang.pad_idx)\n",
    "    \n",
    "    if config.load_pretrained_emb:\n",
    "        assert config.lang.emb_matrix is not None\n",
    "        emb.weight = nn.Parameter(torch.tensor(config.lang.emb_matrix, dtype=torch.float32))\n",
    "        emb.weight.requires_grad = False\n",
    "        \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config: Config, model_type):\n",
    "        \"\"\"\n",
    "        :param model_type: cs / cg\n",
    "        cs: code -> anno\n",
    "        cg: anno -> code\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        assert model_type in ['cs', 'cg']\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        src_cfg = config.anno if model_type == 'cg' else config.code\n",
    "        tgt_cfg = config.code if model_type == 'cg' else config.anno\n",
    "        \n",
    "        # 1. ENCODER\n",
    "        self.src_embedding = get_embeddings(src_cfg)\n",
    "        self.encoder = nn.LSTM(input_size=src_cfg.emb_size,\n",
    "                               hidden_size=src_cfg.lstm_hidden_size,\n",
    "                               dropout=src_cfg.lstm_dropout_p,\n",
    "                               bidirectional=True,\n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.decoder_cell_init_linear = nn.Linear(in_features=2*src_cfg.lstm_hidden_size,\n",
    "                                                  out_features=tgt_cfg.lstm_hidden_size)\n",
    "        \n",
    "        # 2. ATTENTION\n",
    "        # project source encoding to decoder rnn's h space (W from Luong score general)\n",
    "        self.att_src_W = nn.Linear(in_features=2*src_cfg.lstm_hidden_size,\n",
    "                                   out_features=tgt_cfg.lstm_hidden_size,\n",
    "                                   bias=False)\n",
    "        \n",
    "        # transformation of decoder hidden states and context vectors before reading out target words\n",
    "        # this produces the attentional vector in (W from Luong eq. 5)\n",
    "        self.att_vec_W = nn.Linear(in_features=2*src_cfg.lstm_hidden_size + tgt_cfg.lstm_hidden_size,\n",
    "                                   out_features=tgt_cfg.lstm_hidden_size,\n",
    "                                   bias=False)\n",
    "        \n",
    "        # 3. DECODER\n",
    "        self.tgt_embedding = get_embeddings(tgt_cfg)\n",
    "        self.decoder = nn.LSTMCell(input_size=tgt_cfg.emb_size + tgt_cfg.lstm_hidden_size,\n",
    "                                   hidden_size=tgt_cfg.lstm_hidden_size)\n",
    "       \n",
    "        # prob layer over target language\n",
    "        self.readout = nn.Linear(in_features=tgt_cfg.lstm_hidden_size,\n",
    "                                 out_features=len(tgt_cfg.lang),\n",
    "                                 bias=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(tgt_cfg.att_dropout_p)\n",
    "        \n",
    "        # 4. COPY MECHANISM\n",
    "        self.copy_gate = ... # TODO\n",
    "        \n",
    "        # save configs\n",
    "        self.src_cfg = src_cfg\n",
    "        self.tgt_cfg = tgt_cfg\n",
    "        \n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        src: bs, max_src_len\n",
    "        tgt: bs, max_tgt_len\n",
    "        \"\"\"\n",
    "        enc_out, (h0_dec, c0_dec) = self.encode(src)\n",
    "        scores, att_mats = self.decode(enc_out, h0_dec, c0_dec, tgt)\n",
    "        \n",
    "        return scores, att_mats\n",
    "    \n",
    "    \n",
    "    def encode(self, src):\n",
    "        \"\"\"\n",
    "        src : bs x max_src_len (emb look-up indices)\n",
    "        out : bs x max_src_len x 2*hid_size\n",
    "        h/c0: bs x tgt_hid_size\n",
    "        \"\"\"\n",
    "        emb = self.src_embedding(src)\n",
    "        out, (hn, cn) = self.encoder(emb) # hidden is zero by default\n",
    "        \n",
    "        # construct initial state for the decoder\n",
    "        c0_dec = self.decoder_cell_init_linear(torch.cat([cn[0], cn[1]], dim=1))\n",
    "        h0_dec = c0_dec.tanh()\n",
    "        \n",
    "        return out, (h0_dec, c0_dec)\n",
    "    \n",
    "    \n",
    "    def decode(self, src_enc, h0_dec, c0_dec, tgt):\n",
    "        \"\"\"\n",
    "        src_enc: bs, max_src_len, 2*hid_size (== encoder output)\n",
    "        h/c0   : bs, tgt_hid_size\n",
    "        tgt    : bs, max_tgt_len (emb look-up indices)\n",
    "        \n",
    "        scores :\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        scores, att_mats = [], []\n",
    "        \n",
    "        hidden = (h0_dec, c0_dec)\n",
    "        \n",
    "        emb = self.tgt_embedding(tgt) # bs, max_tgt_len, tgt_emb_size\n",
    "        \n",
    "        att_vec = torch.zeros(batch_size, self.tgt_cfg.lstm_hidden_size, requires_grad=False)\n",
    "        \n",
    "        # Luong W*hs: same for each timestep of the decoder\n",
    "        src_enc_att = self.att_src_W(src_enc) # bs, max_src_len, tgt_hid_size\n",
    "        \n",
    "        for t in range(tgt_len):\n",
    "            emb_t = emb[:, t, :]\n",
    "            x = torch.cat([emb_t, att_vec], dim=-1)\n",
    "            h_t, c_t = self.decoder(x, hidden)\n",
    "\n",
    "            ctx_t, att_mat = self.luong_attention(h_t, src_enc, src_enc_att)\n",
    "            \n",
    "            # Luong eq. (5)\n",
    "            att_t = self.att_vec_W(torch.cat([h_t, ctx_t], dim=1))\n",
    "            att_t = att_t.tanh() \n",
    "            att_t = self.dropout(att_t)\n",
    "            \n",
    "            # Luong eq. (6)\n",
    "            score_t = self.readout(att_t)\n",
    "            score_t = F.softmax(score_t, dim=-1)\n",
    "            \n",
    "            scores   += [score_t]\n",
    "            att_mats += [att_mat]\n",
    "            \n",
    "            # for next state t+1\n",
    "            att_vec = att_t\n",
    "            hidden  = (h_t, c_t)\n",
    "        \n",
    "        # bs, max_tgt_len, tgt_vocab_size\n",
    "        scores = torch.stack(scores).permute((1, 0, 2))\n",
    "        \n",
    "        # each element: bs, max_src_len, max_tgt_len\n",
    "        att_mats = torch.cat(att_mats, dim=1)\n",
    "        \n",
    "        return scores, att_mats\n",
    "            \n",
    "        \n",
    "    def luong_attention(self, h_t, src_enc, src_enc_att, mask=None):\n",
    "        \"\"\"\n",
    "        h_t               : bs, hid_size\n",
    "        src_enc (hs)      : bs, max_src_len, 2*src_hid_size \n",
    "        src_enc_att (W*hs): bs, max_src_len, tgt_hid_size\n",
    "        mask              : bs, max_src_len\n",
    "        \n",
    "        ctx_vec    : bs, 2*src_hid_size\n",
    "        att_weight : bs, max_src_len\n",
    "        att_mat    : bs, 1, max_src_len\n",
    "        \"\"\"\n",
    "        \n",
    "        # bs x src_max_len\n",
    "        score = torch.bmm(src_enc_att, h_t.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        if mask:\n",
    "            score.data.masked_fill_(mask, -np.inf)\n",
    "        \n",
    "        att_mat = score.unsqueeze(1)\n",
    "        att_weights = F.softmax(score, dim=-1)\n",
    "        \n",
    "        # sum per timestep\n",
    "        ctx_vec = torch.sum(att_weights.unsqueeze(2) * src_enc, dim=1)\n",
    "        \n",
    "        return ctx_vec, att_mat\n",
    "    \n",
    "    \n",
    "    def translate(self, src):\n",
    "        \"\"\"\n",
    "        Beam search\n",
    "        src: input sequence (anno / code)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_mask(lang):\n",
    "    mask = torch.ones(len(lang))\n",
    "    mask[lang.token2index['<pad>']] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def jensen_shannon_divergence(a1, b1, a_mask, b_mask):\n",
    "    \"\"\"\n",
    "    a       : bs, n, m\n",
    "    b       : bs, m, n\n",
    "    pad_mask: bs, n\n",
    "    \"\"\"\n",
    "    # TODO NO MORE PAD NEEDED\n",
    "    eps, inf = 1e-8, 1e+8\n",
    "    \n",
    "    a = a1.clone()\n",
    "    b = b1.clone()\n",
    "    \n",
    "    bs, n, m = a.shape\n",
    "    assert b.shape == (bs, m, n)\n",
    "    dmax = max(n, m)\n",
    "\n",
    "    \n",
    "    a[a_mask == 1] = -inf\n",
    "    b[b_mask == 1] = -inf\n",
    "#     a.data.masked_fill_(a_mask, -inf)\n",
    "#     b.data.masked_fill_(b_mask, -inf)\n",
    "    \n",
    "    a = F.softmax(a, dim=2) + eps\n",
    "    b = F.softmax(b, dim=2) + eps\n",
    "    \n",
    "    a_ = eps * torch.ones(bs, dmax, dmax)\n",
    "    a_[:, :min(n,dmax), :min(m,dmax)] = a\n",
    "    \n",
    "    b_ = eps * torch.ones(bs, dmax, dmax)\n",
    "    b_[:, :min(m,dmax), :min(n,dmax)] = b\n",
    "    \n",
    "    a_mask_ = torch.ones(bs, dmax)\n",
    "    a_mask_[:, :min(n, dmax)] = a_mask\n",
    "    b_mask_ = torch.ones(bs, dmax)\n",
    "    b_mask_[:, :min(m, dmax)] = b_mask\n",
    "    \n",
    "    a = a_\n",
    "    b = b_\n",
    "    a_mask = a_mask_\n",
    "    b_mask = b_mask_\n",
    "    \n",
    "    kl_a = a * torch.log(a / ((a+b)/2))\n",
    "    kl_b = b * torch.log(b / ((a+b)/2))\n",
    "\n",
    "    kl_a[a_mask == 1] = 0\n",
    "    kl_b[b_mask == 1] = 0\n",
    "#     kl_a.data.masked_fill_(a_mask, 0)\n",
    "#     kl_b.data.masked_fill_(b_mask, 0)\n",
    "    \n",
    "    kl_a = torch.sum(kl_a, dim=2)\n",
    "    kl_b = torch.sum(kl_b, dim=2)\n",
    "    \n",
    "    kl_a = torch.sum(kl_a, dim=1) / torch.sum(1-a_mask, dim=1).float()\n",
    "    kl_b = torch.sum(kl_b, dim=1) / torch.sum(1-b_mask, dim=1).float()\n",
    "    \n",
    "    js_div = (kl_a + kl_b) / 2.0\n",
    "    \n",
    "    return js_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Axy = anno_att_mat.clone()\n",
    "Ayx = code_att_mat.clone()\n",
    "Mxy = anno_mask.clone()\n",
    "Myx = code_mask.clone()\n",
    "\n",
    "jensen_shannon_divergence(\n",
    "    Axy.transpose(2, 1), \n",
    "    Ayx.transpose(2, 1), \n",
    "    Myx, \n",
    "    Mxy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.code_lang.token2count.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {} # {'num_workers': 4, 'pin_memory': True}\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "model = {\n",
    "    'cg': Model(CFG, model_type='cg'),\n",
    "    'cs': Model(CFG, model_type='cs')\n",
    "}\n",
    "\n",
    "opt = {\n",
    "    'cg': O.Adam(lr=0.001, params=filter(lambda p: p.requires_grad, model['cg'].parameters())),\n",
    "    'cs': O.Adam(lr=0.001, params=filter(lambda p: p.requires_grad, model['cs'].parameters()))\n",
    "}\n",
    "\n",
    "crit = {\n",
    "    'cg': nn.CrossEntropyLoss(weight=get_vocab_mask(dataset.code_lang)),\n",
    "    'cs': nn.CrossEntropyLoss(weight=get_vocab_mask(dataset.anno_lang))\n",
    "}\n",
    "\n",
    "__cg_l = 0\n",
    "__cs_l = 0\n",
    "__rep_every = 200\n",
    "\n",
    "for e in range(1000):\n",
    "    for i, (anno, code, anno_lm_p, code_lm_p) in enumerate(train_loader):        \n",
    "        anno_len, code_len = anno.shape[1], code.shape[1]\n",
    "\n",
    "        # binary mask indicating the presence of padding token\n",
    "        anno_mask = torch.tensor(anno == dataset.anno_lang.token2index['<pad>']).byte()\n",
    "        code_mask = torch.tensor(code == dataset.code_lang.token2index['<pad>']).byte()\n",
    "                    \n",
    "        # forward pass\n",
    "        code_pred, code_att_mat = model['cg'](src=anno, tgt=code)\n",
    "        anno_pred, anno_att_mat = model['cs'](src=code, tgt=anno)\n",
    "                \n",
    "        loss = {k: 0 for k in [\n",
    "            'cg', 'cs',         # total\n",
    "            'cg_ce', 'cs_ce',   # cross-entropy\n",
    "            'cg_att', 'cs_att', # attention\n",
    "            'dual'              # common dual loss\n",
    "        ]}\n",
    "        \n",
    "        # CG cross-entropy loss\n",
    "        for t in range(code_len):\n",
    "            loss['cg_ce'] += crit['cg'](code_pred[:, t, :], code[:, t]) / code_len\n",
    "        \n",
    "        # CS cross-entropy loss\n",
    "        for t in range(anno_len):\n",
    "            loss['cs_ce'] += crit['cs'](anno_pred[:, t, :], anno[:, t]) / anno_len\n",
    "\n",
    "        # dual loss: P(x,y)\n",
    "        loss['dual'] = ((code_lm_p - loss['cs_ce']) - (anno_lm_p - loss['cg_ce'])) ** 2\n",
    "                \n",
    "        # attention loss: JSD\n",
    "        loss['cg_att'] = jensen_shannon_divergence(anno_att_mat, \n",
    "                                                   code_att_mat, \n",
    "                                                   anno_mask, \n",
    "                                                   code_mask)\n",
    "        \n",
    "        loss['cs_att'] = jensen_shannon_divergence(anno_att_mat.transpose(2,1), \n",
    "                                                   code_att_mat.transpose(2,1), \n",
    "                                                   code_mask, \n",
    "                                                   anno_mask)\n",
    "                \n",
    "        att_loss = loss['cg_att'] + loss['cs_att']\n",
    "        \n",
    "        loss['cg'] = torch.mean(loss['cg_ce'] + 0.01  * loss['dual'] + 0.1  * att_loss)\n",
    "        loss['cs'] = torch.mean(loss['cs_ce'] + 0.001 * loss['dual'] + 0.01 * att_loss)\n",
    "        \n",
    "        opt['cg'].zero_grad()\n",
    "        loss['cg'].backward(retain_graph=True)\n",
    "        opt['cg'].step()\n",
    "        \n",
    "        opt['cs'].zero_grad()\n",
    "        loss['cs'].backward()\n",
    "        opt['cs'].step()\n",
    "        \n",
    "        __cg_l += loss['cg'].item() / __rep_every\n",
    "        __cs_l += loss['cs'].item() / __rep_every\n",
    "        \n",
    "        if e % 100 == 0:\n",
    "            print(f'Epoch {e:>5d} | Batch {i:>5d} | cg {__cg_l:6.5f} | cs {__cs_l:6.5f}')\n",
    "            __cg_l, __cs_l = 0, 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                ws = dataset.code_lang.to_tokens(code_pred.argmax(dim=-1))\n",
    "                for i, w in enumerate(ws):\n",
    "                    print(f'\\t{i}: {\" \".join(w)}')\n",
    "                print('\\t'+'-'*80)\n",
    "                ws = dataset.anno_lang.to_tokens(anno_pred.argmax(dim=-1))\n",
    "                for i, w in enumerate(ws):\n",
    "                    print(f'\\t{i}: {\" \".join(w)}')\n",
    "                print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
