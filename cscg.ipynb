{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './language_model/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as O\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from django import Django\n",
    "from config import Config\n",
    "from language_model.lm_train import train_language_model\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width=160, indent=2, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_home(x):\n",
    "    return os.path.join(os.environ['HOME'], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR   = from_home('workspace/ml-data/msc-research')\n",
    "DJANGO_DIR = os.path.join(ROOT_DIR, 'raw-datasets/testing')\n",
    "# DJANGO_DIR = os.path.join(ROOT_DIR, 'raw-datasets/django')\n",
    "EMB_DIR    = os.path.join(ROOT_DIR, 'embeddings')\n",
    "\n",
    "CFG = Config() # main config\n",
    "\n",
    "# sub-config for dataset\n",
    "CFG.dataset_config = Config()\n",
    "CFG.dataset_config.__dict__ = {\n",
    "    'root_dir': DJANGO_DIR,\n",
    "    'anno_min_freq': 1,\n",
    "    'code_min_freq': 1,\n",
    "    'anno_seq_maxlen': 20,\n",
    "    'code_seq_maxlen': 10,\n",
    "    'emb_file': os.path.join(EMB_DIR, 'glove.6B.50d.txt.pickle'),\n",
    "}\n",
    "\n",
    "dataset = Django(config=CFG.dataset_config)\n",
    "\n",
    "# sub-config for NL intents\n",
    "CFG.anno = Config() \n",
    "CFG.anno.__dict__ = {\n",
    "    'lstm_hidden_size': 128,\n",
    "    'lstm_dropout_p': 0.0,\n",
    "    'att_dropout_p': 0.0,\n",
    "    'lang': dataset.anno_lang,\n",
    "    'load_pretrained_emb': True,\n",
    "    'emb_size': 50,\n",
    "}\n",
    "\n",
    "# sub-config for source code\n",
    "CFG.code = Config() \n",
    "CFG.code.__dict__ = {\n",
    "    'lstm_hidden_size': 128,\n",
    "    'lstm_dropout_p': 0.0,\n",
    "    'att_dropout_p': 0.0,\n",
    "    'lang': dataset.code_lang,\n",
    "    'load_pretrained_emb': False,\n",
    "    'emb_size': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute LM probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train/test/valid splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset.train_test_valid_split(test_p=1/5, valid_p=1/5, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train language model\n",
    "\n",
    "**Note:** Must do this for both anno and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.language_model = Config()\n",
    "CFG.language_model.__dict__ = {\n",
    "    'dataset'     : 'django',\n",
    "    'model'       : 'LSTM', # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU, Transformer)\n",
    "    'n_head'      : None,   # number of heads in the enc/dec of the Transformers\n",
    "    'emb_size'    : 10,     # size of the word embeddings\n",
    "    'n_hid'       : 32,     # number of hidden units per layer\n",
    "    'n_layers'    : 1,      # number of layers\n",
    "    'lr'          : 0.1,    # initial learning rate\n",
    "    'clip'        : 0.25,   # gradient clipping\n",
    "    'bptt'        : 20,     # seq len\n",
    "    'dropout_p'   : 0.0,    # dropout applied to layers\n",
    "    'tied'        : False,  # whether to tie the word embeddings and softmax weights\n",
    "    'log_interval': 10,\n",
    "    'epochs'      : 10, # upper epoch limit\n",
    "    'batch_size'  : 4,\n",
    "    'seed'        : None # for reproducibility\n",
    "}\n",
    "\n",
    "CFG.language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_cfg = CFG.language_model\n",
    "\n",
    "for kind in ['anno', 'code']:\n",
    "    print(f'Training LM for {kind}\\n')\n",
    "\n",
    "    lm_cfg.kind = kind\n",
    "    lm_cfg.save_path = f'./data/lm/lm-{lm_cfg.dataset}-{lm_cfg.kind}.pt' # path to save the final model\n",
    "    \n",
    "    num_tokens = len(dataset)\n",
    "    \n",
    "    train_language_model(lm_cfg, \n",
    "                         num_tokens=len(getattr(dataset, f'{kind}_lang')),\n",
    "                         train_nums=torch.stack(splits[kind]['train']),\n",
    "                         test_nums=torch.stack(splits[kind]['test']),\n",
    "                         valid_nums=torch.stack(splits[kind]['valid']))\n",
    "    \n",
    "    print('*' * 120, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute LM probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_root_dir = './data/lm'\n",
    "lm_paths = {\n",
    "    'anno': f'{lm_root_dir}/lm-{lm_cfg.dataset}-anno.pt',\n",
    "    'code': f'{lm_root_dir}/lm-{lm_cfg.dataset}-code.pt'\n",
    "}\n",
    "\n",
    "for f in lm_paths.values():\n",
    "    assert os.path.exists(f), f'Language Model: file <{f}> does not exist!'\n",
    "    \n",
    "_ = dataset.compute_lm_probs(lm_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual CS/CG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(config: Config):\n",
    "    emb = nn.Embedding(len(config.lang), config.emb_size, padding_idx=config.lang.pad_idx)\n",
    "    \n",
    "    if config.load_pretrained_emb:\n",
    "        assert config.lang.emb_matrix is not None\n",
    "        emb.weight = nn.Parameter(torch.tensor(config.lang.emb_matrix, dtype=torch.float32))\n",
    "        emb.weight.requires_grad = False\n",
    "        \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config: Config, model_type):\n",
    "        \"\"\"\n",
    "        :param model_type: cs / cg\n",
    "        cs: code -> anno\n",
    "        cg: anno -> code\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        assert model_type in ['cs', 'cg']\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        src_cfg = config.anno if model_type == 'cg' else config.code\n",
    "        tgt_cfg = config.code if model_type == 'cg' else config.anno\n",
    "        \n",
    "        # 1. ENCODER\n",
    "        self.src_embedding = get_embeddings(src_cfg)\n",
    "        self.encoder = nn.LSTM(input_size=src_cfg.emb_size,\n",
    "                               hidden_size=src_cfg.lstm_hidden_size,\n",
    "                               dropout=src_cfg.lstm_dropout_p,\n",
    "                               bidirectional=True,\n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.decoder_cell_init_linear = nn.Linear(in_features=2*src_cfg.lstm_hidden_size,\n",
    "                                                  out_features=tgt_cfg.lstm_hidden_size)\n",
    "        \n",
    "        # 2. ATTENTION\n",
    "        # project source encoding to decoder rnn's h space (W from Luong score general)\n",
    "        self.att_src_W = nn.Linear(in_features=2*src_cfg.lstm_hidden_size,\n",
    "                                   out_features=tgt_cfg.lstm_hidden_size,\n",
    "                                   bias=False)\n",
    "        \n",
    "        # transformation of decoder hidden states and context vectors before reading out target words\n",
    "        # this produces the attentional vector in (W from Luong eq. 5)\n",
    "        self.att_vec_W = nn.Linear(in_features=2*src_cfg.lstm_hidden_size + tgt_cfg.lstm_hidden_size,\n",
    "                                   out_features=tgt_cfg.lstm_hidden_size,\n",
    "                                   bias=False)\n",
    "        \n",
    "        # 3. DECODER\n",
    "        self.tgt_embedding = get_embeddings(tgt_cfg)\n",
    "        self.decoder = nn.LSTMCell(input_size=tgt_cfg.emb_size + tgt_cfg.lstm_hidden_size,\n",
    "                                   hidden_size=tgt_cfg.lstm_hidden_size)\n",
    "       \n",
    "        # prob layer over target language\n",
    "        self.readout = nn.Linear(in_features=tgt_cfg.lstm_hidden_size,\n",
    "                                 out_features=len(tgt_cfg.lang),\n",
    "                                 bias=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(tgt_cfg.att_dropout_p)\n",
    "        \n",
    "        # save configs\n",
    "        self.src_cfg = src_cfg\n",
    "        self.tgt_cfg = tgt_cfg\n",
    "        \n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        src: bs, max_src_len\n",
    "        tgt: bs, max_tgt_len\n",
    "        \"\"\"\n",
    "        enc_out, (h0_dec, c0_dec) = self.encode(src)\n",
    "        scores, att_mats = self.decode(enc_out, h0_dec, c0_dec, tgt)\n",
    "        \n",
    "        return scores, att_mats\n",
    "    \n",
    "    \n",
    "    def encode(self, src):\n",
    "        \"\"\"\n",
    "        src : bs x max_src_len (emb look-up indices)\n",
    "        out : bs x max_src_len x 2*hid_size\n",
    "        h/c0: bs x tgt_hid_size\n",
    "        \"\"\"\n",
    "        emb = self.src_embedding(src)\n",
    "        out, (hn, cn) = self.encoder(emb) # hidden is zero by default\n",
    "        \n",
    "        # construct initial state for the decoder\n",
    "        c0_dec = self.decoder_cell_init_linear(torch.cat([cn[0], cn[1]], dim=1))\n",
    "        h0_dec = c0_dec.tanh()\n",
    "        \n",
    "        return out, (h0_dec, c0_dec)\n",
    "    \n",
    "    \n",
    "    def decode(self, src_enc, h0_dec, c0_dec, tgt):\n",
    "        \"\"\"\n",
    "        src_enc: bs, max_src_len, 2*hid_size (== encoder output)\n",
    "        h/c0   : bs, tgt_hid_size\n",
    "        tgt    : bs, max_tgt_len (emb look-up indices)\n",
    "        \n",
    "        scores :\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        scores, att_mats = [], []\n",
    "        \n",
    "        hidden = (h0_dec, c0_dec)\n",
    "        \n",
    "        emb = self.tgt_embedding(tgt) # bs, max_tgt_len, tgt_emb_size\n",
    "        \n",
    "        att_vec = torch.zeros(batch_size, self.tgt_cfg.lstm_hidden_size, requires_grad=False)\n",
    "        \n",
    "        # Luong W*hs: same for each timestep of the decoder\n",
    "        src_enc_att = self.att_src_W(src_enc) # bs, max_src_len, tgt_hid_size\n",
    "        \n",
    "        for t in range(tgt_len):\n",
    "            emb_t = emb[:, t, :]\n",
    "            x = torch.cat([emb_t, att_vec], dim=-1)\n",
    "            h_t, c_t = self.decoder(x, hidden)\n",
    "\n",
    "            ctx_t, att_mat = self.luong_attention(h_t, src_enc, src_enc_att)\n",
    "            \n",
    "            # Luong eq. (5)\n",
    "            att_t = self.att_vec_W(torch.cat([h_t, ctx_t], dim=1))\n",
    "            att_t = att_t.tanh() \n",
    "            att_t = self.dropout(att_t)\n",
    "            \n",
    "            # Luong eq. (6)\n",
    "            score_t = self.readout(att_t)\n",
    "            score_t = F.softmax(score_t, dim=-1)\n",
    "            \n",
    "            scores   += [score_t]\n",
    "            att_mats += [att_mat]\n",
    "            \n",
    "            # for next state t+1\n",
    "            att_vec = att_t\n",
    "            hidden  = (h_t, c_t)\n",
    "        \n",
    "        # bs, max_tgt_len, tgt_vocab_size\n",
    "        scores = torch.stack(scores).permute((1, 0, 2))\n",
    "        # each element: bs, 1, max_tgt_len\n",
    "        att_mats = att_mats[:-1]\n",
    "        \n",
    "        return scores, att_mats\n",
    "            \n",
    "        \n",
    "    def luong_attention(self, h_t, src_enc, src_enc_att, mask=None):\n",
    "        \"\"\"\n",
    "        h_t               : bs, hid_size\n",
    "        src_enc (hs)      : bs, max_src_len, 2*src_hid_size \n",
    "        src_enc_att (W*hs): bs, max_src_len, tgt_hid_size\n",
    "        mask              : bs, max_src_len\n",
    "        \n",
    "        ctx_vec    : bs, 2*src_hid_size\n",
    "        att_weight : bs, max_src_len\n",
    "        att_mat    : bs, 1, max_src_len\n",
    "        \"\"\"\n",
    "        \n",
    "        # bs x src_max_len\n",
    "        score = torch.bmm(src_enc_att, h_t.unsqueeze(2)).squeeze(2)\n",
    "        \n",
    "        if mask:\n",
    "            score.data.masked_fill_(mask, -np.inf)\n",
    "        \n",
    "        att_mat = score.unsqueeze(1)\n",
    "        att_weights = F.softmax(score, dim=-1)\n",
    "        \n",
    "        # sum per timestep\n",
    "        ctx_vec = torch.sum(att_weights.unsqueeze(2) * src_enc, dim=1)\n",
    "        \n",
    "        return ctx_vec, att_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_mask(lang):\n",
    "    mask = torch.ones(len(lang))\n",
    "    mask[lang.token2index['<pad>']] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def jensen_shannon_divergence(a, b, mask, length):\n",
    "    \"\"\"\n",
    "    a     :\n",
    "    b     :\n",
    "    mask  :\n",
    "    length:\n",
    "    \"\"\"\n",
    "    eps, inf = 1e-8, 1e+8\n",
    "    \n",
    "    length = torch.tensor(length).float()\n",
    "    \n",
    "    a.data.masked_fill_(mask, -inf)\n",
    "    b.data.masked_fill_(mask, -inf)\n",
    "    \n",
    "    a = F.softmax(a, dim=2) + eps\n",
    "    b = F.softmax(b, dim=2) + eps\n",
    "    \n",
    "    kl_a = a * torch.log(a / ((a+b)/2))\n",
    "    kl_b = b * torch.log(b / ((a+b)/2))\n",
    "    kl_a.data.masked_fill_(mask, 0)\n",
    "    kl_b.data.masked_fill_(mask, 0)\n",
    "    \n",
    "    kl_a = torch.sum(kl_a, dim=2)\n",
    "    kl_b = torch.sum(kl_b, dim=2)\n",
    "    kl_a = torch.sum(kl_a, dim=1) / length\n",
    "    kl_b = torch.sum(kl_b, dim=1) / length\n",
    "    \n",
    "    js_div = (kl_a + kl_b) / 2.0\n",
    "    \n",
    "    return js_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "$\\widehat{code} = M_{CG}(anno, code)$\n",
    "\n",
    "$\\widehat{anno} = M_{CS}(code, anno)$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cg_model = ... (y -> x)\n",
    "cs_model = ... (x -> y)\n",
    "\n",
    "for x, y in data:\n",
    "    y_ = cs_model(x)\n",
    "    x_ = cg_model(y)\n",
    "    \n",
    "    lxy   = ...\n",
    "    lyx   = ...\n",
    "    ldual = ...\n",
    "    latt1 = ...\n",
    "    latt2 = ...\n",
    "    latt  = l1 + l2\n",
    "    \n",
    "    lcs = lxy + a1*ldual + b1*latt\n",
    "    lcg = lyx + a2*ldual + b2*latt\n",
    "    \n",
    "    lcs.backward()\n",
    "    lcg.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {} # {'num_workers': 4, 'pin_memory': True}\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=False, **kwargs)\n",
    "\n",
    "model = {\n",
    "    'cg': Model(CFG, model_type='cg'),\n",
    "    'cs': Model(CFG, model_type='cs')\n",
    "}\n",
    "\n",
    "opt = {\n",
    "    'cg': O.Adam(lr=0.001, params=filter(lambda p: p.requires_grad, model['cg'].parameters())),\n",
    "    'cs': O.Adam(lr=0.001, params=filter(lambda p: p.requires_grad, model['cs'].parameters()))\n",
    "}\n",
    "\n",
    "crit = {\n",
    "    'cg': nn.CrossEntropyLoss(weight=get_vocab_mask(dataset.code_lang)),\n",
    "    'cs': nn.CrossEntropyLoss(weight=get_vocab_mask(dataset.anno_lang))\n",
    "}\n",
    "\n",
    "\n",
    "for e in range(1):\n",
    "    for i, (anno, code) in enumerate(train_loader):        \n",
    "        anno_len, code_len = anno.shape[1], code.shape[1]\n",
    "            \n",
    "        code_, c_am = model['cg'](src=anno, tgt=code)\n",
    "        anno_, a_am = model['cs'](src=code, tgt=anno)\n",
    "        \n",
    "        loss = {k: 0 for k in [\n",
    "            'cg', 'cs',         # total\n",
    "            'cg_ce', 'cs_ce',   # cross-entropy\n",
    "            'cg_att', 'cs_att', # attention\n",
    "            'dual'              # common dual loss\n",
    "        ]}\n",
    "        \n",
    "        for t in range(code_len):\n",
    "            loss['cg_ce'] += crit['cg'](code_[:, t, :], code[:, t]) / code_len\n",
    "        \n",
    "        for t in range(anno_len):\n",
    "            loss['cs_ce'] += crit['cs'](anno_[:, t, :], anno[:, t]) / anno_len\n",
    "\n",
    "        \n",
    "        loss['dual'] = ...\n",
    "        loss['cg_att'] = jensen_shannon_divergence(...)\n",
    "        loss['cs_att'] = jensen_shannon_divergence(...)\n",
    "        att_loss = loss['cg_att'] + loss['cs_att']\n",
    "        \n",
    "        loss['cg'] = loss['cg_ce'] + 0.1 * loss['cg_att'] + 0.2 * loss['dual']\n",
    "        loss['cs'] = loss['cs_ce'] + 0.3 * loss['cs_att'] + 0.4 * loss['dual']\n",
    "        \n",
    "        \n",
    "        if e % 400 == 0:\n",
    "            print(f'{e:>5d} | cg {loss[\"cg\"].item():6.5f} | cs {loss[\"cs\"].item():6.5f}')\n",
    "            with torch.no_grad():\n",
    "                ws = dataset.code_lang.to_tokens(code_.argmax(dim=-1))\n",
    "                for i, w in enumerate(ws):\n",
    "                    print(f'\\t{i}: {\" \".join(w)}')\n",
    "                print('\\t'+'-'*80)\n",
    "                ws = dataset.anno_lang.to_tokens(anno_.argmax(dim=-1))\n",
    "                for i, w in enumerate(ws):\n",
    "                    print(f'\\t{i}: {\" \".join(w)}')\n",
    "                print()\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
